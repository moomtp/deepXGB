{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model on metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Import torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Import matplotlib for visulization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pandas as pd  # 資料分析套件\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### var setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../model/best_model_resnet18_7.pth\"\n",
    "\n",
    "dataset_path = \"../HAM10000/meta_img_data\"\n",
    "\n",
    "groundtruth_file = '../HAM10000/GroundTruth.csv'\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有的值都在範圍內：\n"
     ]
    }
   ],
   "source": [
    "from pytorch_helper.CreateFileLableDict import CreateFileLableDict\n",
    "filename_to_label_dict = CreateFileLableDict(groundtruth_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_helper.CustomImageDataset import CustomImageDataset\n",
    "\n",
    "# 假設您的圖片和標籤字典如下\n",
    "img_dir = dataset_path\n",
    "\n",
    "# list all filename from file\n",
    "all_files = [f for f in os.listdir(dataset_path) if os.path.isfile(os.path.join(dataset_path, f))]\n",
    "\n",
    "# list all filename from dict\n",
    "# all_files = list(filename_to_label_dict.keys())\n",
    "\n",
    "\n",
    "num_total_samples = len(all_files)\n",
    "split_ratio = 0.8  # 80% 的数据用于训练，20% 用于测试\n",
    "\n",
    "# 随机打乱数据集\n",
    "random.shuffle(all_files)\n",
    "\n",
    "# 计算分割点\n",
    "split_idx = int(num_total_samples * split_ratio)\n",
    "\n",
    "# 分割数据集\n",
    "train_files = all_files[:split_idx]\n",
    "test_files = all_files[split_idx:]\n",
    "\n",
    "transform224 = torchvision.transforms.Compose([\n",
    "    transforms.Resize(size=(224,224)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "    # 其他轉換\n",
    "])\n",
    "\n",
    "\n",
    "# 创建训练集和测试集的数据加载器\n",
    "train_dataset = CustomImageDataset(img_dir=img_dir, file_to_label_dict={file: filename_to_label_dict[file] for file in train_files}, transform=transform224)\n",
    "test_dataset = CustomImageDataset(img_dir=img_dir, file_to_label_dict={file: filename_to_label_dict[file] for file in test_files}, transform=transform224)\n",
    "all_dataset = CustomImageDataset(img_dir=img_dir, file_to_label_dict={file: filename_to_label_dict[file] for file in all_files}, transform=transform224)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "all_data_loader = DataLoader(all_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init training object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\E\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\E\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5921973272206935, 0.8339370873074101, 0.8277992243345038)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "from pytorch_helper.helperFunctions import switchLastLayer\n",
    "from pytorch_helper.TrainHelper import TrainingHelper\n",
    "\n",
    "model_0 = models.resnet18(pretrained=True)     # 使用內建的 model \n",
    "\n",
    "# switchLastLayer(model_0, num_classes=7)\n",
    "\n",
    "# change fully connected layer to 7\n",
    "num_ftrs = model_0.fc.in_features\n",
    "model_0.fc = nn.Linear(num_ftrs, 7)\n",
    "\n",
    "\n",
    "model_0.load_state_dict(torch.load(model_path))\n",
    "\n",
    "optimizer = torch.optim.SGD(model_0.parameters(), lr = 0.001) # 選擇你想用的 optimizer\n",
    "# optimizer = torch.optim.Adam(model_VGG16.parameters(), lr =0.01)\n",
    "\n",
    "# Loss function\n",
    "loss_fn = nn.CrossEntropyLoss()                # 選擇想用的 loss functionmodel_vgg16 = \n",
    "\n",
    "model_0 = model_0.to(device)\n",
    "\n",
    "\n",
    "\n",
    "trainingHelper = TrainingHelper(model=model_0,\n",
    "                                train_dataloader=train_data_loader,\n",
    "                                test_dataloader=all_data_loader,\n",
    "                                loss_fn=loss_fn,\n",
    "                                optimizer=optimizer,\n",
    "                                device=device)\n",
    "\n",
    "print(trainingHelper.test_step())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove model's fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [1, 512]                  --\n",
       "├─Conv2d: 1-1                            [1, 64, 112, 112]         9,408\n",
       "├─BatchNorm2d: 1-2                       [1, 64, 112, 112]         128\n",
       "├─ReLU: 1-3                              [1, 64, 112, 112]         --\n",
       "├─MaxPool2d: 1-4                         [1, 64, 56, 56]           --\n",
       "├─Sequential: 1-5                        [1, 64, 56, 56]           --\n",
       "│    └─BasicBlock: 2-1                   [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-1                  [1, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-3                    [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-4                  [1, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-6                    [1, 64, 56, 56]           --\n",
       "│    └─BasicBlock: 2-2                   [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-7                  [1, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-9                    [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-10                 [1, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-12                   [1, 64, 56, 56]           --\n",
       "├─Sequential: 1-6                        [1, 128, 28, 28]          --\n",
       "│    └─BasicBlock: 2-3                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-13                 [1, 128, 28, 28]          73,728\n",
       "│    │    └─BatchNorm2d: 3-14            [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-15                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-16                 [1, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-17            [1, 128, 28, 28]          256\n",
       "│    │    └─Sequential: 3-18             [1, 128, 28, 28]          8,448\n",
       "│    │    └─ReLU: 3-19                   [1, 128, 28, 28]          --\n",
       "│    └─BasicBlock: 2-4                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-20                 [1, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-21            [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-22                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-23                 [1, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-24            [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-25                   [1, 128, 28, 28]          --\n",
       "├─Sequential: 1-7                        [1, 256, 14, 14]          --\n",
       "│    └─BasicBlock: 2-5                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-26                 [1, 256, 14, 14]          294,912\n",
       "│    │    └─BatchNorm2d: 3-27            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-28                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-29                 [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-30            [1, 256, 14, 14]          512\n",
       "│    │    └─Sequential: 3-31             [1, 256, 14, 14]          33,280\n",
       "│    │    └─ReLU: 3-32                   [1, 256, 14, 14]          --\n",
       "│    └─BasicBlock: 2-6                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-33                 [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-34            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-35                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-36                 [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-37            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-38                   [1, 256, 14, 14]          --\n",
       "├─Sequential: 1-8                        [1, 512, 7, 7]            --\n",
       "│    └─BasicBlock: 2-7                   [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-39                 [1, 512, 7, 7]            1,179,648\n",
       "│    │    └─BatchNorm2d: 3-40            [1, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-41                   [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-42                 [1, 512, 7, 7]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43            [1, 512, 7, 7]            1,024\n",
       "│    │    └─Sequential: 3-44             [1, 512, 7, 7]            132,096\n",
       "│    │    └─ReLU: 3-45                   [1, 512, 7, 7]            --\n",
       "│    └─BasicBlock: 2-8                   [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-46                 [1, 512, 7, 7]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-47            [1, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-48                   [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-49                 [1, 512, 7, 7]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-50            [1, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-51                   [1, 512, 7, 7]            --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [1, 512, 1, 1]            --\n",
       "├─Identity: 1-10                         [1, 512]                  --\n",
       "==========================================================================================\n",
       "Total params: 11,176,512\n",
       "Trainable params: 11,176,512\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.81\n",
       "==========================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 39.74\n",
       "Params size (MB): 44.71\n",
       "Estimated Total Size (MB): 85.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model_0.to('cpu')\n",
    "\n",
    "model_0.fc = torch.nn.Identity()\n",
    "\n",
    "summary(model_0, input_size=[1,3,224,224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0011, 0.0023, 0.0009, 0.0013, 0.0017, 0.0012, 0.0009, 0.0010, 0.0014,\n",
      "         0.0018, 0.0019, 0.0011, 0.0018, 0.0009, 0.0012, 0.0009, 0.0010, 0.0014,\n",
      "         0.0010, 0.0009, 0.0012, 0.0009, 0.0019, 0.0009, 0.0018, 0.0013, 0.0010,\n",
      "         0.0016, 0.0030, 0.0012, 0.0010, 0.0016, 0.0022, 0.0011, 0.0009, 0.0009,\n",
      "         0.0012, 0.0014, 0.0017, 0.0010, 0.0021, 0.0009, 0.0010, 0.0009, 0.0035,\n",
      "         0.0023, 0.0119, 0.0009, 0.0040, 0.0009, 0.0014, 0.0009, 0.0011, 0.0009,\n",
      "         0.0015, 0.0015, 0.0046, 0.0047, 0.0009, 0.0014, 0.0060, 0.0044, 0.0031,\n",
      "         0.0011, 0.0009, 0.0010, 0.0028, 0.0042, 0.0089, 0.0010, 0.0037, 0.0019,\n",
      "         0.0010, 0.0009, 0.0010, 0.0010, 0.0015, 0.0029, 0.0018, 0.0022, 0.0012,\n",
      "         0.0014, 0.0041, 0.0020, 0.0011, 0.0015, 0.0011, 0.0040, 0.0016, 0.0010,\n",
      "         0.0018, 0.0038, 0.0010, 0.0011, 0.0010, 0.0033, 0.0040, 0.0009, 0.0009,\n",
      "         0.0010, 0.0024, 0.0052, 0.0009, 0.0009, 0.0015, 0.0013, 0.0017, 0.0026,\n",
      "         0.0052, 0.0010, 0.0019, 0.0009, 0.0009, 0.0033, 0.0012, 0.0011, 0.0009,\n",
      "         0.0064, 0.0010, 0.0010, 0.0010, 0.0009, 0.0009, 0.0032, 0.0009, 0.0015,\n",
      "         0.0009, 0.0010, 0.0010, 0.0014, 0.0009, 0.0009, 0.0011, 0.0037, 0.0019,\n",
      "         0.0097, 0.0010, 0.0036, 0.0009, 0.0011, 0.0010, 0.0011, 0.0027, 0.0018,\n",
      "         0.0009, 0.0009, 0.0015, 0.0035, 0.0066, 0.0061, 0.0009, 0.0009, 0.0010,\n",
      "         0.0019, 0.0009, 0.0029, 0.0009, 0.0009, 0.0027, 0.0013, 0.0012, 0.0010,\n",
      "         0.0017, 0.0040, 0.0015, 0.0019, 0.0011, 0.0009, 0.0009, 0.0027, 0.0025,\n",
      "         0.0013, 0.0042, 0.0009, 0.0009, 0.0009, 0.0012, 0.0010, 0.0021, 0.0009,\n",
      "         0.0038, 0.0009, 0.0033, 0.0010, 0.0009, 0.0013, 0.0009, 0.0019, 0.0021,\n",
      "         0.0049, 0.0014, 0.0010, 0.0045, 0.0150, 0.0009, 0.0010, 0.0023, 0.0010,\n",
      "         0.0010, 0.0009, 0.0055, 0.0010, 0.0019, 0.0010, 0.0013, 0.0013, 0.0024,\n",
      "         0.0012, 0.0011, 0.0009, 0.0012, 0.0009, 0.0009, 0.0023, 0.0009, 0.0009,\n",
      "         0.0010, 0.0032, 0.0026, 0.0020, 0.0011, 0.0009, 0.0011, 0.0022, 0.0027,\n",
      "         0.0009, 0.0040, 0.0009, 0.0021, 0.0017, 0.0034, 0.0018, 0.0030, 0.0011,\n",
      "         0.0049, 0.0010, 0.0014, 0.0010, 0.0023, 0.0010, 0.0010, 0.0013, 0.0012,\n",
      "         0.0010, 0.0009, 0.0071, 0.0061, 0.0011, 0.0009, 0.0009, 0.0010, 0.0015,\n",
      "         0.0010, 0.0043, 0.0011, 0.0018, 0.0010, 0.0009, 0.0014, 0.0012, 0.0010,\n",
      "         0.0028, 0.0018, 0.0009, 0.0010, 0.0033, 0.0010, 0.0019, 0.0039, 0.0010,\n",
      "         0.0027, 0.0025, 0.0268, 0.0009, 0.0014, 0.0010, 0.0009, 0.0025, 0.0012,\n",
      "         0.0020, 0.0016, 0.0009, 0.0030, 0.0011, 0.0010, 0.0014, 0.0009, 0.0009,\n",
      "         0.0047, 0.0011, 0.0009, 0.0014, 0.0009, 0.0009, 0.0010, 0.0028, 0.0011,\n",
      "         0.0017, 0.0013, 0.0021, 0.0014, 0.0015, 0.0053, 0.0009, 0.0015, 0.0010,\n",
      "         0.0009, 0.0027, 0.0011, 0.0010, 0.0009, 0.0036, 0.0010, 0.0014, 0.0020,\n",
      "         0.0046, 0.0010, 0.0025, 0.0009, 0.0010, 0.0024, 0.0029, 0.0009, 0.0009,\n",
      "         0.0026, 0.0009, 0.0019, 0.0010, 0.0020, 0.0009, 0.0014, 0.0017, 0.0009,\n",
      "         0.0038, 0.0011, 0.0011, 0.0011, 0.0009, 0.0016, 0.0029, 0.0009, 0.0012,\n",
      "         0.0012, 0.0012, 0.0012, 0.0009, 0.0026, 0.0012, 0.0057, 0.0011, 0.0034,\n",
      "         0.0013, 0.0019, 0.0009, 0.0014, 0.0012, 0.0011, 0.0009, 0.0018, 0.0009,\n",
      "         0.0010, 0.0034, 0.0021, 0.0012, 0.0009, 0.0114, 0.0034, 0.0010, 0.0016,\n",
      "         0.0030, 0.0014, 0.0009, 0.0015, 0.0018, 0.0013, 0.0017, 0.0011, 0.0014,\n",
      "         0.0010, 0.0064, 0.0009, 0.0017, 0.0010, 0.0010, 0.0052, 0.0009, 0.0009,\n",
      "         0.0025, 0.0009, 0.0013, 0.0021, 0.0009, 0.0020, 0.0009, 0.0025, 0.0031,\n",
      "         0.0017, 0.0016, 0.0009, 0.0009, 0.0042, 0.0017, 0.0011, 0.0010, 0.0012,\n",
      "         0.0018, 0.0010, 0.0022, 0.0012, 0.0009, 0.0016, 0.0016, 0.0029, 0.0018,\n",
      "         0.0013, 0.0013, 0.0011, 0.0009, 0.0031, 0.0017, 0.0010, 0.0009, 0.0029,\n",
      "         0.0009, 0.0034, 0.0009, 0.0011, 0.0010, 0.0022, 0.0046, 0.0009, 0.0011,\n",
      "         0.0010, 0.0017, 0.0045, 0.0072, 0.0016, 0.0020, 0.0014, 0.0022, 0.0009,\n",
      "         0.0017, 0.0009, 0.0025, 0.0009, 0.0010, 0.0029, 0.0010, 0.0057, 0.0085,\n",
      "         0.0009, 0.0009, 0.0009, 0.0012, 0.0010, 0.0009, 0.0011, 0.0041, 0.0019,\n",
      "         0.0055, 0.0010, 0.0020, 0.0009, 0.0011, 0.0011, 0.0022, 0.0009, 0.0010,\n",
      "         0.0010, 0.0019, 0.0040, 0.0009, 0.0019, 0.0019, 0.0009, 0.0012, 0.0023,\n",
      "         0.0010, 0.0010, 0.0026, 0.0010, 0.0031, 0.0043, 0.0010, 0.0010, 0.0015,\n",
      "         0.0010, 0.0010, 0.0027, 0.0068, 0.0009, 0.0029, 0.0009, 0.0017, 0.0012,\n",
      "         0.0009, 0.0052, 0.0024, 0.0011, 0.0088, 0.0010, 0.0015, 0.0011, 0.0009,\n",
      "         0.0020, 0.0020, 0.0011, 0.0024, 0.0036, 0.0017, 0.0051, 0.0013]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "from pytorch_helper.helperFunctions import img2tensor, flattenTensor\n",
    "\n",
    "img_path = \"../HAM10000/images/ISIC_0024306.jpg\"\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "input_data = img2tensor(img).to(device)\n",
    "\n",
    "\n",
    "output = model_0(input_data)\n",
    "\n",
    "print(torch.softmax(output, dim=1))\n",
    "\n",
    "\n",
    "\n",
    "# output = conv_layer(input_data)\n",
    "# print(input_data.shape)\n",
    "# print(output.shape)\n",
    "\n",
    "# output = conv_block(input_data)\n",
    "# output = conv_block_2(output)\n",
    "# input_data = img2tensor(image_path)\n",
    "# input_data = input_data.to(device)\n",
    "\n",
    "# model_VGG16.eval()\n",
    "# with torch.no_grad():\n",
    "#     output = model_VGG16(input_data)\n",
    "# prob = torch.softmax(output, dim=1)\n",
    "# print(input_data.shape)\n",
    "# print(output.shape)\n",
    "# print(prob)\n",
    "# print(flattenTensor(output).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate CNN output data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_helper\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelperFunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generateModelOutputs , saveCsv\n\u001b[1;32m----> 6\u001b[0m input_folder \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_path\u001b[49m\n\u001b[0;32m      7\u001b[0m output_csvfile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../resnet_output.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m model_0\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_path' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "from pytorch_helper.helperFunctions import generateModelOutputs , saveCsv\n",
    "\n",
    "input_folder = dataset_path\n",
    "output_csvfile_name = \"../resnet_output.csv\"\n",
    "\n",
    "model_0.to(\"cpu\")\n",
    "\n",
    "res = []\n",
    "\n",
    "# open every img\n",
    "start = time.time()\n",
    "res = generateModelOutputs(model_0, dataset_path)\n",
    "# for filename in os.listdir(input_folder):\n",
    "\n",
    "#     image_path  = os.path.join(input_folder, filename)\n",
    "#     # print(image_path)\n",
    "#     img = cv2.imread(image_path)\n",
    "#     img = img2tensor(img)\n",
    "\n",
    "#     # model setting and eval\n",
    "#     model_0.eval()\n",
    "#     with torch.no_grad():\n",
    "#         tensor = model_0(img)\n",
    "    \n",
    "#     tensor = flattenTensor(tensor)\n",
    "#     vec = tensor.tolist()\n",
    "\n",
    "#     vec = [filename] + vec\n",
    "#     res.append(vec)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"time cost : {}\".format(end - start))\n",
    "\n",
    "# add header\n",
    "\n",
    "# print(res)\n",
    "with open(output_csvfile_name, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    # try:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(res)\n",
    "    # except Exception as e:\n",
    "    #     logging.error(\"csv error : %s\" , e)\n",
    "    #     print('csv encoding error')\n",
    "\n",
    "\n",
    "# add head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
